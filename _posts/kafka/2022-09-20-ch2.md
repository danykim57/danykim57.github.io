---
title:  "Kafka tutorial"
header:
teaser: "https://farm5.staticflickr.com/4076/4940499208_b79b77fb0a_z.jpg"
categories:
  - Kafka
tags:
  - Kafka
---


A record or a message is data that goes in and out from Kafka.

Kafka records are consist of key, value, and timestamp.

The records are stored in the unit of "Topic".

Topic is partitioned and replicated.

Example of the topic creation

```
bin/kafka-topics.sh --create --bootstrap-server localhost:9094
--topic kinaction_helloworld --partitions 3 --replication-factor 3
```

Example of the topic list

```
bin/kafka-topics.sh --list --bootstrap-server localhost:9094
```

Example of the topic detalis

```
bin/kafka-topics.sh --bootstrap-server localhost:9094 \
  --describe --topic kinaction_helloworld
```

Topic is consist of partitions.

Each partition is an ordered, immutable, sequence of records.

Topic > Partition > record (Logical view)

Topic > Partition > segment (Physical view)

By marking with an offset, consumer keeps how far it read.

Message brokers: The one acts like servers, and handles the commit logs.

Consumer: The one retrieves messages from Kafka

Example of the consumer creation

```
bin/kafka-console-consumer.sh --bootstrap-server localhost:9094 \ --topic kinaction_helloworld --from-beginning
```
Producer: The one sends messages to Kafka

Example of the producer creation

```
bin/kafka-console-producer.sh --bootstrap-server localhost:9094 \ --topic kinaction_helloworld
```

There is no such thing as a default producer in Kafka, but the Apis that use

Kafka implement producer, for example, Flume, Connect and Stream

Example of the producer send a message
```
Alert alert = new Alert(1, "Stage 1", "CRITICAL", "Stage 1 stopped");
ProducerRecord<Alert, String> producerRecord =
new ProducerRecord<Alert, String>
("kinaction_alert", alert, alert.getAlertMessage());
producer.send(producerRecord,
new AlertCallback());   
```

- The existence of ProducerRecord is necessary.
- Alert Object is a key for the message
- send method to invoke the function

Example of the consumer consumes a message

```
consumer.subscribe(List.of("kinaction_audit"));
while (keepConsuming) {
var records = consumer.
poll(Duration.ofMillis(250));
for (ConsumerRecord<String, String> record : records) {
log.info("kinaction_info offset = {}, kinaction_value = {}",
record.offset(), record.value());
OffsetAndMetadata offsetMeta =
new OffsetAndMetadata(++record.offset(), "");
Map<TopicPartition, OffsetAndMetadata> kaOffsetMap = new HashMap<>();
kaOffsetMap.put(new TopicPartition("kinaction_audit",
record.partition()), offsetMeta);
consumer.commitSync(kaOffsetMap);
}
}
```

Partitions:

 - One of the partitions is a leader
 - Others are followers

Zookeeper:

 - Take the responsibility of leader selection algo.

How Kafka is fast on reading?
 - Using memory as a tool for page cache

Client Consumer example
```java
public class HelloWorldConsumer {
final static Logger log = LoggerFactory.getLogger(HelloWorldConsumer.class);
  private volatile boolean keepConsuming = true;
  public static void main(String[] args) {
    Properties kaProperties = new Properties();
    kaProperties.put("bootstrap.servers",
Properties are set the same way as producers.
"localhost:9092,localhost:9093,localhost:9094"); kaProperties.put("group.id", "kinaction_helloconsumer"); kaProperties.put("enable.auto.commit", "true"); kaProperties.put("auto.commit.interval.ms", "1000"); kaProperties.put("key.deserializer",
"org.apache.kafka.common.serialization.StringDeserializer"); kaProperties.put("value.deserializer",
"org.apache.kafka.common.serialization.StringDeserializer");
HelloWorldConsumer helloWorldConsumer = new HelloWorldConsumer(); helloWorldConsumer.consume(kaProperties);
Runtime.getRuntime().
addShutdownHook(new Thread(helloWorldConsumer::shutdown));

      private void consume(Properties kaProperties) {
          try (KafkaConsumer<String, String> consumer =
                       new KafkaConsumer<>(kaProperties)) {
              consumer.subscribe(
                      List.of(
                              "kinaction_helloworld"
                      ) );
              The consumer tells Kafka what topics itâ€™s interested in.
              while (keepConsuming) {
                  ConsumerRecords<String, String> records =
                          consumer.poll(Duration.ofMillis(250));
                  for (ConsumerRecord<String, String> record :
                          Polls for new messages as they come in
                  records) {
                      log.info("kinaction_info offset = {}, kinaction_value = {}",
                              record.offset(), record.value());
                  }
              } }
      }
      private void shutdown() {
          keepConsuming = false;
      }
```
